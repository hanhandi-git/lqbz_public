<think>
我需要创建针对HTTP和gRPC的连接池的Python代码示例。连接池是为了重用连接，减少建立连接的开销，尤其是对于这两种基于TCP的协议来说尤其重要。

对于HTTP连接池，我可以使用Python的`requests`库和`urllib3`库(requests内部使用的)。对于gRPC连接池，可以使用gRPC Python库并创建一个管理Channel的连接池实现。

让我给出两个完整的实现:

1. HTTP连接池 - 使用`requests`的`Session`对象，它内部维护连接池
2. gRPC连接池 - 实现一个自定义的连接池来管理gRPC的Channel对象

我会专注于清晰、简洁和有效的代码，包括适当的错误处理和资源管理。
</think>

# 实现HTTP和gRPC连接池

连接池是提高应用性能的重要技术，它通过重用TCP连接来减少连接建立和拆除的开销。下面我将分别实现HTTP和gRPC的连接池。

## HTTP连接池

HTTP连接池可以使用`requests`库的`Session`对象，它内部已经实现了连接复用：

```python
import requests
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional


class HTTPConnectionPool:
    def __init__(self, pool_size: int = 10, timeout: int = 5):
        """
        HTTP连接池实现
        
        Args:
            pool_size: 连接池中最大连接数
            timeout: 连接和请求超时时间(秒)
        """
        self.pool_size = pool_size
        self.timeout = timeout
        self.sessions: Dict[str, requests.Session] = {}
        self._lock = ThreadPoolExecutor(max_workers=1)
    
    def _get_or_create_session(self, base_url: str) -> requests.Session:
        """获取或创建指向特定主机的session"""
        if base_url not in self.sessions:
            session = requests.Session()
            # 配置连接池参数
            adapter = requests.adapters.HTTPAdapter(
                pool_connections=self.pool_size,
                pool_maxsize=self.pool_size,
                max_retries=3
            )
            session.mount('http://', adapter)
            session.mount('https://', adapter)
            self.sessions[base_url] = session
        
        return self.sessions[base_url]
    
    def request(self, method: str, url: str, **kwargs) -> requests.Response:
        """
        发送HTTP请求，自动复用连接
        
        Args:
            method: HTTP方法 (GET, POST等)
            url: 完整URL
            **kwargs: 传递给requests.request的其他参数
        
        Returns:
            HTTP响应对象
        """
        # 从URL中提取域名作为连接池的key
        from urllib.parse import urlparse
        parsed_url = urlparse(url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
        
        # 设置默认超时
        if 'timeout' not in kwargs:
            kwargs['timeout'] = self.timeout
            
        # 获取session并发送请求
        session = self._get_or_create_session(base_url)
        return session.request(method, url, **kwargs)
    
    def get(self, url: str, **kwargs) -> requests.Response:
        return self.request('GET', url, **kwargs)
    
    def post(self, url: str, **kwargs) -> requests.Response:
        return self.request('POST', url, **kwargs)
    
    def close(self) -> None:
        """关闭所有连接池中的连接"""
        for session in self.sessions.values():
            session.close()
        self.sessions.clear()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# 使用示例
def http_pool_example():
    pool = HTTPConnectionPool(pool_size=20)
    
    try:
        # 发起多个请求到同一服务器（会复用连接）
        for i in range(5):
            response = pool.get('https://httpbin.org/get', params={'id': i})
            print(f"Request {i} status: {response.status_code}")
            print(f"Connection: {response.headers.get('Connection', 'Unknown')}")
    finally:
        pool.close()


if __name__ == "__main__":
    http_pool_example()
```

## gRPC连接池

gRPC连接池需要我们自己实现，因为官方库没有直接提供连接池机制：

```python
import grpc
import time
import threading
from typing import Dict, Any, Optional, Callable, Tuple
from concurrent import futures

# 假设我们有一个proto生成的服务定义
# import my_service_pb2
# import my_service_pb2_grpc


class GRPCConnectionPool:
    def __init__(self, max_size: int = 10, max_idle_time: int = 300):
        """
        gRPC连接池实现
        
        Args:
            max_size: 连接池中最大连接数
            max_idle_time: 连接最大空闲时间(秒)，超过则关闭
        """
        self.max_size = max_size
        self.max_idle_time = max_idle_time
        self.pool: Dict[str, list] = {}  # {target: [(channel, last_used_time, in_use)]}
        self.lock = threading.RLock()
        
        # 启动守护线程定期清理空闲连接
        self.cleanup_thread = threading.Thread(target=self._cleanup_idle_connections, daemon=True)
        self.cleanup_thread.start()
    
    def get_channel(self, target: str, options: Optional[list] = None) -> grpc.Channel:
        """
        从连接池获取一个gRPC channel
        
        Args:
            target: 目标服务地址 (如 "localhost:50051")
            options: gRPC channel选项
            
        Returns:
            gRPC Channel对象，包装在PooledChannel中以便归还
        """
        with self.lock:
            # 初始化目标服务的连接列表
            if target not in self.pool:
                self.pool[target] = []
            
            # 查找可用连接
            for i, (channel, last_used, in_use) in enumerate(self.pool[target]):
                if not in_use:
                    # 更新连接状态
                    self.pool[target][i] = (channel, time.time(), True)
                    return PooledChannel(channel, target, self)
            
            # 如果没有可用连接且未达到最大连接数，创建新连接
            if len(self.pool[target]) < self.max_size:
                # 创建新的gRPC channel
                channel = grpc.insecure_channel(target, options=options or [])
                self.pool[target].append((channel, time.time(), True))
                return PooledChannel(channel, target, self)
            
            # 达到最大连接数，等待或抛出异常
            raise ConnectionError(f"No available connections for {target}, max pool size reached")
    
    def release_channel(self, target: str, channel: grpc.Channel) -> None:
        """将连接归还到连接池"""
        with self.lock:
            if target in self.pool:
                for i, (ch, _, in_use) in enumerate(self.pool[target]):
                    if ch is channel and in_use:
                        # 更新连接状态为未使用
                        self.pool[target][i] = (ch, time.time(), False)
                        return
    
    def _cleanup_idle_connections(self) -> None:
        """定期清理空闲连接的守护线程"""
        while True:
            time.sleep(60)  # 每分钟检查一次
            
            with self.lock:
                current_time = time.time()
                for target in list(self.pool.keys()):
                    # 过滤出需要保留的连接
                    active_connections = []
                    for channel, last_used, in_use in self.pool[target]:
                        if in_use or (current_time - last_used) < self.max_idle_time:
                            active_connections.append((channel, last_used, in_use))
                        else:
                            # 关闭长时间空闲的连接
                            channel.close()
                    
                    # 更新连接池
                    if active_connections:
                        self.pool[target] = active_connections
                    else:
                        del self.pool[target]
    
    def close(self) -> None:
        """关闭所有连接"""
        with self.lock:
            for target, connections in self.pool.items():
                for channel, _, _ in connections:
                    channel.close()
            self.pool.clear()


class PooledChannel:
    """包装gRPC channel以支持自动归还到连接池"""
    
    def __init__(self, channel: grpc.Channel, target: str, pool: GRPCConnectionPool):
        self.channel = channel
        self.target = target
        self.pool = pool
        self.closed = False
    
    def __getattr__(self, name):
        """代理所有对channel的属性访问"""
        return getattr(self.channel, name)
    
    def close(self) -> None:
        """归还连接到连接池而不是真正关闭"""
        if not self.closed:
            self.pool.release_channel(self.target, self.channel)
            self.closed = True
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# 使用示例
def grpc_pool_example():
    # 创建gRPC连接池
    pool = GRPCConnectionPool(max_size=10)
    
    try:
        # 从连接池获取连接
        with pool.get_channel("localhost:50051") as channel:
            # 创建stub (假设我们有一个服务定义)
            # stub = my_service_pb2_grpc.MyServiceStub(channel)
            
            # 调用gRPC方法
            # response = stub.MyMethod(my_service_pb2.MyRequest(data="test"))
            # print(f"Response: {response}")
            
            print("gRPC call would be made here")
        
        # 连接会自动归还到连接池
    finally:
        # 关闭所有连接
        pool.close()


if __name__ == "__main__":
    grpc_pool_example()
```

## 实际使用建议

1. **HTTP连接池**:
   - 在大多数情况下，直接使用`requests.Session`即可，它已经内置了连接池功能
   - 如果需要更精细的控制，可以使用上面的自定义连接池

2. **gRPC连接池**:
   - gRPC的Channel已经设计为长连接，在简单场景下可以直接复用单个Channel
   - 在复杂应用中，使用连接池可以更好地控制连接数量和生命周期
   - 考虑使用gRPC的keepalive机制确保长连接的健康状态

3. **异步支持**:
   - 如果您使用异步编程，可以用`aiohttp`替代`requests`
   - 对于gRPC，可以使用`grpcio-asyncio`实现异步连接池

这些连接池实现会帮助您的应用更有效地利用TCP连接，避免频繁建立连接带来的开销，对于高并发服务尤其重要。



<think>
我需要用C++实现HTTP和gRPC的连接池。我将分开实现这两种连接池，提供完整且可用的代码。

HTTP连接池在C++中通常会使用像libcurl这样的库，而gRPC连接池则需要使用gRPC C++库。下面我将为每个实现提供代码。
</think>

# C++实现HTTP和gRPC连接池

下面我将用C++实现HTTP和gRPC的连接池。这些实现需要依赖libcurl（HTTP）和gRPC C++库。

## HTTP连接池（基于libcurl）

```cpp
#include <curl/curl.h>
#include <string>
#include <vector>
#include <map>
#include <mutex>
#include <memory>
#include <chrono>
#include <thread>
#include <functional>
#include <iostream>
#include <atomic>

// 回调函数处理HTTP响应
size_t WriteCallback(void* contents, size_t size, size_t nmemb, std::string* userp) {
    userp->append((char*)contents, size * nmemb);
    return size * nmemb;
}

class HTTPConnectionPool {
public:
    struct HTTPResponse {
        long status_code;
        std::string body;
        std::map<std::string, std::string> headers;
    };

    struct Connection {
        CURL* handle;
        std::chrono::steady_clock::time_point last_used;
        bool in_use;
    };

    HTTPConnectionPool(size_t max_connections = 10, long connection_timeout = 30, 
                      long idle_timeout_seconds = 60)
        : max_connections_(max_connections), 
          connection_timeout_(connection_timeout),
          idle_timeout_(idle_timeout_seconds),
          running_(true) {
        
        // 初始化curl全局环境
        curl_global_init(CURL_GLOBAL_ALL);
        
        // 启动清理线程
        cleanup_thread_ = std::thread(&HTTPConnectionPool::cleanupIdleConnections, this);
    }

    ~HTTPConnectionPool() {
        // 停止清理线程
        running_ = false;
        if (cleanup_thread_.joinable()) {
            cleanup_thread_.join();
        }
        
        // 清理所有连接
        std::lock_guard<std::mutex> lock(mutex_);
        for (auto& host_entry : connection_pool_) {
            for (auto& conn : host_entry.second) {
                curl_easy_cleanup(conn.handle);
            }
        }
        connection_pool_.clear();
        
        // 清理curl全局环境
        curl_global_cleanup();
    }

    HTTPResponse get(const std::string& url, 
                    const std::map<std::string, std::string>& headers = {}) {
        return request("GET", url, "", headers);
    }

    HTTPResponse post(const std::string& url, const std::string& data, 
                     const std::map<std::string, std::string>& headers = {}) {
        return request("POST", url, data, headers);
    }

    HTTPResponse request(const std::string& method, const std::string& url, 
                        const std::string& data = "",
                        const std::map<std::string, std::string>& headers = {}) {
        // 从URL提取主机名
        std::string host = extractHost(url);
        // 获取连接
        CURL* curl = getConnection(host);
        
        // 设置请求选项
        curl_easy_setopt(curl, CURLOPT_URL, url.c_str());
        curl_easy_setopt(curl, CURLOPT_TIMEOUT, connection_timeout_);
        curl_easy_setopt(curl, CURLOPT_CONNECTTIMEOUT, connection_timeout_);
        
        // 设置请求方法
        if (method == "POST") {
            curl_easy_setopt(curl, CURLOPT_POST, 1L);
            curl_easy_setopt(curl, CURLOPT_POSTFIELDS, data.c_str());
            curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, data.length());
        } else if (method != "GET") {
            curl_easy_setopt(curl, CURLOPT_CUSTOMREQUEST, method.c_str());
            if (!data.empty()) {
                curl_easy_setopt(curl, CURLOPT_POSTFIELDS, data.c_str());
                curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, data.length());
            }
        }
        
        // 设置响应接收函数
        std::string response_body;
        curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
        curl_easy_setopt(curl, CURLOPT_WRITEDATA, &response_body);
        
        // 设置HTTP头
        struct curl_slist* curl_headers = nullptr;
        for (const auto& header : headers) {
            std::string header_line = header.first + ": " + header.second;
            curl_headers = curl_slist_append(curl_headers, header_line.c_str());
        }
        
        if (curl_headers) {
            curl_easy_setopt(curl, CURLOPT_HTTPHEADER, curl_headers);
        }
        
        // 执行请求
        CURLcode res = curl_easy_perform(curl);
        
        // 释放headers
        if (curl_headers) {
            curl_slist_free_all(curl_headers);
        }
        
        // 处理响应
        HTTPResponse response;
        if (res == CURLE_OK) {
            long status_code;
            curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE, &status_code);
            response.status_code = status_code;
            response.body = response_body;
            
            // 获取响应头
            // 这是简化版，完整实现需要注册回调收集所有头信息
        } else {
            response.status_code = -1;
            response.body = std::string("CURL error: ") + curl_easy_strerror(res);
        }
        
        // 归还连接
        releaseConnection(host, curl);
        
        return response;
    }

private:
    CURL* getConnection(const std::string& host) {
        std::lock_guard<std::mutex> lock(mutex_);
        
        // 检查是否有可用连接
        auto& connections = connection_pool_[host];
        for (auto& conn : connections) {
            if (!conn.in_use) {
                conn.in_use = true;
                conn.last_used = std::chrono::steady_clock::now();
                return conn.handle;
            }
        }
        
        // 如果当前连接数小于最大值，创建新连接
        if (connections.size() < max_connections_) {
            CURL* curl = curl_easy_init();
            if (curl) {
                // 配置连接以重用
                curl_easy_setopt(curl, CURLOPT_TCP_KEEPALIVE, 1L);
                curl_easy_setopt(curl, CURLOPT_FORBID_REUSE, 0L);
                
                Connection conn{curl, std::chrono::steady_clock::now(), true};
                connections.push_back(conn);
                return curl;
            }
        }
        
        // 等待连接释放...（简化实现，实际应该使用条件变量等待）
        // 这里为了简单，直接创建一个新连接超出池大小
        CURL* curl = curl_easy_init();
        if (curl) {
            Connection conn{curl, std::chrono::steady_clock::now(), true};
            connections.push_back(conn);
            return curl;
        }
        
        throw std::runtime_error("Failed to get curl connection");
    }

    void releaseConnection(const std::string& host, CURL* curl) {
        std::lock_guard<std::mutex> lock(mutex_);
        
        auto it = connection_pool_.find(host);
        if (it != connection_pool_.end()) {
            for (auto& conn : it->second) {
                if (conn.handle == curl) {
                    // 重置curl状态以便重用
                    curl_easy_reset(curl);
                    conn.in_use = false;
                    conn.last_used = std::chrono::steady_clock::now();
                    return;
                }
            }
        }
    }

    void cleanupIdleConnections() {
        while (running_) {
            std::this_thread::sleep_for(std::chrono::seconds(30)); // 每30秒检查一次
            
            std::lock_guard<std::mutex> lock(mutex_);
            auto now = std::chrono::steady_clock::now();
            
            for (auto& host_entry : connection_pool_) {
                auto& connections = host_entry.second;
                
                // 移除长时间空闲的连接
                connections.erase(
                    std::remove_if(connections.begin(), connections.end(),
                        [&](const Connection& conn) {
                            if (!conn.in_use && 
                                std::chrono::duration_cast<std::chrono::seconds>(
                                    now - conn.last_used).count() > idle_timeout_) {
                                curl_easy_cleanup(conn.handle);
                                return true;
                            }
                            return false;
                        }
                    ),
                    connections.end()
                );
            }
        }
    }

    std::string extractHost(const std::string& url) {
        // 简化的URL解析，提取主机名
        size_t start = url.find("://");
        if (start == std::string::npos) {
            return "";
        }
        
        start += 3; // 跳过 "://"
        size_t end = url.find("/", start);
        if (end == std::string::npos) {
            end = url.length();
        }
        
        return url.substr(start, end - start);
    }

    size_t max_connections_;
    long connection_timeout_;
    long idle_timeout_;
    std::map<std::string, std::vector<Connection>> connection_pool_;
    std::mutex mutex_;
    std::thread cleanup_thread_;
    std::atomic<bool> running_;
};

// 使用示例
void httpPoolExample() {
    HTTPConnectionPool pool(10, 30, 120);
    
    try {
        // 发起GET请求
        auto response = pool.get("https://httpbin.org/get");
        std::cout << "GET Status: " << response.status_code << std::endl;
        std::cout << "Body: " << response.body << std::endl;
        
        // 发起POST请求
        std::map<std::string, std::string> headers = {
            {"Content-Type", "application/json"}
        };
        response = pool.post("https://httpbin.org/post", 
                           "{\"message\":\"Hello from C++\"}", 
                           headers);
        std::cout << "POST Status: " << response.status_code << std::endl;
        std::cout << "Body: " << response.body << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "Exception: " << e.what() << std::endl;
    }
}
```

## gRPC连接池

```cpp
#include <grpcpp/grpcpp.h>
#include <string>
#include <vector>
#include <map>
#include <mutex>
#include <memory>
#include <chrono>
#include <thread>
#include <functional>
#include <iostream>
#include <atomic>
#include <condition_variable>

class GrpcConnectionPool {
public:
    struct ChannelInfo {
        std::shared_ptr<grpc::Channel> channel;
        std::chrono::steady_clock::time_point last_used;
        bool in_use;
    };

    GrpcConnectionPool(size_t max_connections = 10, 
                     int max_idle_seconds = 300) 
        : max_connections_(max_connections),
          max_idle_seconds_(max_idle_seconds),
          running_(true) {
        
        // 启动清理线程
        cleanup_thread_ = std::thread(&GrpcConnectionPool::cleanupIdleConnections, this);
    }

    ~GrpcConnectionPool() {
        // 停止清理线程
        running_ = false;
        cleanup_cv_.notify_one();
        
        if (cleanup_thread_.joinable()) {
            cleanup_thread_.join();
        }
        
        // 清理所有连接
        std::lock_guard<std::mutex> lock(mutex_);
        connection_pool_.clear();
    }

    // 获取一个Channel
    std::shared_ptr<grpc::Channel> getChannel(const std::string& target, 
                                             const grpc::ChannelArguments& args = grpc::ChannelArguments()) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        auto& channels = connection_pool_[target];
        
        // 查找可用连接
        for (auto& info : channels) {
            if (!info.in_use) {
                info.in_use = true;
                info.last_used = std::chrono::steady_clock::now();
                // 包装通道用于自动归还
                return std::shared_ptr<grpc::Channel>(info.channel.get(), 
                    [this, target, ch = info.channel](grpc::Channel*) {
                        releaseChannel(target, ch);
                    });
            }
        }
        
        // 如果没有可用连接且未达到最大值，创建新连接
        if (channels.size() < max_connections_) {
            auto channel = grpc::CreateCustomChannel(
                target, grpc::InsecureChannelCredentials(), args);
            
            ChannelInfo info{channel, std::chrono::steady_clock::now(), true};
            channels.push_back(info);
            
            // 包装通道用于自动归还
            return std::shared_ptr<grpc::Channel>(channel.get(), 
                [this, target, ch = channel](grpc::Channel*) {
                    releaseChannel(target, ch);
                });
        }
        
        // 等待连接可用
        auto wait_pred = [this, &channels]() -> bool {
            for (auto& info : channels) {
                if (!info.in_use) return true;
            }
            return false;
        };
        
        // 等待连接释放或超时
        if (cv_.wait_for(lock, std::chrono::seconds(5), wait_pred)) {
            // 找到可用连接
            for (auto& info : channels) {
                if (!info.in_use) {
                    info.in_use = true;
                    info.last_used = std::chrono::steady_clock::now();
                    return std::shared_ptr<grpc::Channel>(info.channel.get(), 
                        [this, target, ch = info.channel](grpc::Channel*) {
                            releaseChannel(target, ch);
                        });
                }
            }
        }
        
        // 超时，创建一个额外的连接（即使超过了池大小）
        auto channel = grpc::CreateCustomChannel(
            target, grpc::InsecureChannelCredentials(), args);
        
        ChannelInfo info{channel, std::chrono::steady_clock::now(), true};
        channels.push_back(info);
        
        return std::shared_ptr<grpc::Channel>(channel.get(), 
            [this, target, ch = channel](grpc::Channel*) {
                releaseChannel(target, ch);
            });
    }

private:
    void releaseChannel(const std::string& target, std::shared_ptr<grpc::Channel> channel) {
        std::lock_guard<std::mutex> lock(mutex_);
        
        auto it = connection_pool_.find(target);
        if (it != connection_pool_.end()) {
            for (auto& info : it->second) {
                if (info.channel == channel) {
                    info.in_use = false;
                    info.last_used = std::chrono::steady_clock::now();
                    cv_.notify_one();
                    return;
                }
            }
        }
    }

    void cleanupIdleConnections() {
        while (running_) {
            // 等待通知或超时
            std::unique_lock<std::mutex> lock(mutex_);
            cleanup_cv_.wait_for(lock, std::chrono::minutes(1), 
                                [this] { return !running_; });
            
            if (!running_) break;
            
            auto now = std::chrono::steady_clock::now();
            
            for (auto it = connection_pool_.begin(); it != connection_pool_.end();) {
                auto& channels = it->second;
                
                // 移除长时间空闲的连接
                channels.erase(
                    std::remove_if(channels.begin(), channels.end(),
                        [&](const ChannelInfo& info) {
                            if (!info.in_use && 
                                std::chrono::duration_cast<std::chrono::seconds>(
                                    now - info.last_used).count() > max_idle_seconds_) {
                                return true;
                            }
                            return false;
                        }
                    ),
                    channels.end()
                );
                
                // 如果该目标没有连接了，移除目标
                if (channels.empty()) {
                    it = connection_pool_.erase(it);
                } else {
                    ++it;
                }
            }
        }
    }

    size_t max_connections_;
    int max_idle_seconds_;
    std::map<std::string, std::vector<ChannelInfo>> connection_pool_;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::condition_variable cleanup_cv_;
    std::thread cleanup_thread_;
    std::atomic<bool> running_;
};

// 使用示例 - 假设我们有一个gRPC服务的定义
// 你需要适配你自己的proto文件生成的服务存根
void grpcPoolExample() {
    GrpcConnectionPool pool(10, 300);
    
    try {
        // 获取gRPC通道
        auto channel = pool.getChannel("localhost:50051");
        
        // 创建服务存根
        // auto stub = YourService::NewStub(channel);
        
        // 调用gRPC方法
        // grpc::ClientContext context;
        // YourRequest request;
        // request.set_message("Hello");
        // YourResponse response;
        // auto status = stub->YourMethod(&context, request, &response);
        
        // if (status.ok()) {
        //     std::cout << "Response: " << response.message() << std::endl;
        // } else {
        //     std::cerr << "RPC failed: " << status.error_message() << std::endl;
        // }
        
        std::cout << "gRPC call would be made here" << std::endl;
        
        // 连接会自动归还到连接池
    } catch (const std::exception& e) {
        std::cerr << "Exception: " << e.what() << std::endl;
    }
}

int main() {
    // 测试HTTP连接池
    httpPoolExample();
    
    // 测试gRPC连接池
    grpcPoolExample();
    
    return 0;
}
```

## 实现说明与使用建议

### HTTP连接池（基于libcurl）

1. **依赖**：需要安装libcurl库
   ```bash
   # Ubuntu/Debian
   sudo apt-get install libcurl4-openssl-dev
   
   # CentOS/RHEL
   sudo yum install libcurl-devel
   
   # macOS
   brew install curl
   ```

2. **编译命令**：
   ```bash
   g++ -o http_pool http_pool.cpp -lcurl -std=c++14 -pthread
   ```

3. **关键特点**：
   - 基于libcurl实现连接池
   - 支持连接复用
   - 自动清理空闲连接
   - 支持超时配置

### gRPC连接池

1. **依赖**：需要安装gRPC C++库
   ```bash
   # 参考gRPC官方文档安装
   # https://grpc.io/docs/languages/cpp/quickstart/
   ```

2. **编译命令**：
   ```bash
   g++ -o grpc_pool grpc_pool.cpp -lgrpc++ -lgrpc -lprotobuf -std=c++14 -pthread
   ```

3. **关键特点**：
   - 支持基于目标地址的连接分组
   - 连接自动归还机制
   - 使用引用计数智能指针管理通道生命周期
   - 定期清理空闲连接

### 使用建议

1. **异步支持**：
   - 对于HTTP，libcurl支持异步操作，可以使用multi接口
   - 对于gRPC，可以使用gRPC异步API

2. **线程安全**：
   - 这两个连接池实现都是线程安全的
   - 使用互斥锁保护共享资源

3. **错误处理**：
   - 实际应用中应增强错误处理和重试逻辑
   - 添加断路器模式防止级联故障

4. **监控**：
   - 在生产环境中，应添加连接池使用情况的监控
   - 跟踪连接创建、复用和关闭的指标

这些C++连接池实现可以显著提高高并发应用的性能，通过复用TCP连接减少连接建立和TLS握手的开销。
